{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc6a0e84",
   "metadata": {},
   "source": [
    "# developed by: Vanshika Maithani\n",
    "# 4th Semester\n",
    "# Graphic Era Hill University\n",
    "# Topic : House Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a195d79",
   "metadata": {},
   "source": [
    "# IMPORTING REQUIRED PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762e78d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np  \n",
    "import seaborn as sb   #for graphs,plots\n",
    "import matplotlib.pyplot as plt  #data visualization\n",
    "# sklearn/ scikit-learn : implement various machine learning models for regression, classification, clustering\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.linear_model import LinearRegression  \n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.neighbors import KNeighborsRegressor   \n",
    "from sklearn.ensemble import RandomForestRegressor  \n",
    "from sklearn import metrics   # For evaluating model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1825606d",
   "metadata": {},
   "source": [
    "# LOADING DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b29350",
   "metadata": {},
   "source": [
    "- The dataset is California Housing Prices Data (5 new features!).  \n",
    "- Median house prices for California districts derived from the 1990 census.\n",
    "- It is a modified version of the California Housing Data used in the paper Pace, R. Kelley, and Ronald Barry.\n",
    "- Loading the dataset with the help of pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef1618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"California_Houses.csv\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd2fea",
   "metadata": {},
   "source": [
    "# TAKING A LOOK AT THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7523d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bffa4c",
   "metadata": {},
   "source": [
    "__We can see that each row has 14 different attributes:__\n",
    "\n",
    "    -> Median_House_Value        :  It has median house value within a block (measured in US Dollars).\n",
    "    -> Median_Income             :  It describes the median income for households (measured in 10000 of US Dollars).\n",
    "    -> Median_Age                :  It describes about the median age of a house within a block.\n",
    "    -> Tot_Rooms                 :  It describes the total number of rooms in a block.\n",
    "    -> Tot_Bedrooms              :  It describes the total number of bedrooms in a block.\n",
    "    -> Population                :  It shows the total number of people residing within a block.\n",
    "    -> Households                :  It describes the number of people residing within a home unit, for a block.\n",
    "    -> Latitude                  :  A measure of latitude for a house.\n",
    "    -> Longitude                 :  A measure of longitude for a house.\n",
    "    -> Distance_to_coast         :  Distance to the nearest coast point.\n",
    "    -> Distance_to_LA            :  Distance to the centre of Los Angeles.\n",
    "    -> Distance_to_SanDiego      :  Distance to the centre of San Diego.\n",
    "    -> Distance_to_SanJose       :  Distance to the centre of San Jose.\n",
    "    -> Distance_to_SanFrancisco  :  Distance to the centre of San Francisco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ca9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info() \n",
    "# function provides a summary of the DataFrame,\n",
    "#including the column names, the data types of each column, the number of non-null values, and memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e57dd58",
   "metadata": {},
   "source": [
    "__We can see that:__\n",
    "- There are 20640 instances in the dataset.\n",
    "- There are no missing values.\n",
    "- All the values are numeric (float or int)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe() \n",
    "#it gives statistical summary of the numerical column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c410f78",
   "metadata": {},
   "source": [
    "__This shows the statistical summaries of our dataset.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d68f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(6, 2, figsize=[20, 40])\n",
    "#This line creates a figure with 6 rows and 2 columns of subplots, and sets the size of the figure to 20 inches in width and 40 inches in height. \n",
    "#The fig variable represents the entire figure,\n",
    "#and the axis variable is a 2-dimensional array representing the individual subplots.\n",
    "sb.histplot(dataset, x=\"Median_House_Value\", ax=axis[0,0])\n",
    "sb.histplot(dataset, x=\"Median_Income\", ax=axis[0,1])\n",
    "sb.histplot(dataset, x=\"Median_Age\", ax=axis[1,0])\n",
    "sb.histplot(dataset, x=\"Tot_Rooms\", ax=axis[1,1])\n",
    "sb.histplot(dataset, x=\"Tot_Bedrooms\", ax=axis[2,0])\n",
    "sb.histplot(dataset, x=\"Population\", ax=axis[2,1])\n",
    "sb.histplot(dataset, x=\"Households\", ax=axis[3,0])\n",
    "sb.histplot(dataset, x=\"Distance_to_coast\", ax=axis[3,1])\n",
    "sb.histplot(dataset, x=\"Distance_to_LA\", ax=axis[4,0])\n",
    "sb.histplot(dataset, x=\"Distance_to_SanDiego\", ax=axis[4,1])\n",
    "sb.histplot(dataset, x=\"Distance_to_SanJose\", ax=axis[5,0])\n",
    "sb.histplot(dataset, x=\"Distance_to_SanFrancisco\", ax=axis[5,1])\n",
    "#These lines use the sb.histplot() function from seaborn to create histograms of \n",
    "#different columns from the dataset DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a134b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sb.scatterplot(data=dataset, x=\"Longitude\", y=\"Latitude\")\n",
    "#function from the seaborn library to create a scatter plot of the geographical coordinates (longitude and latitude) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442b7014",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__This is the graphical visulisation of the dataset attributes.__\n",
    "- We observe that the attributes have very different scales so we need to perform feature scaling.\n",
    "- Many histograms are tail heavy i.e. they extend much farther to the right of the median than to the left. This may make it a bit harder for some Machine Learning algorithms to detect patterns. We need to transform these to have more bell-shaped distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d785f7d",
   "metadata": {},
   "source": [
    "# CORRELATION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcf0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = dataset.corr(method=\"pearson\")  #this gives correlation between various data.(+ve or -ve)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))  #The fig variable represents the entire figure, \n",
    "#and the ax variable represents the axis object.\n",
    "\n",
    "sb.heatmap(matrix,annot=True, linewidths=0.5, ax=ax)\n",
    "\n",
    "#heatmap is a representation of how strongly the variables are related to each other.\n",
    "#with positive correlations represented by warmer colors (e.g., red)\n",
    "#and negative correlations represented by cooler colors (e.g., blue).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d3ef8",
   "metadata": {},
   "source": [
    "# SPLITTING DATA FOR TRAINING / TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e13f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_features = dataset.drop(\"Median_House_Value\", axis=1)\n",
    "dataset_labels = dataset[\"Median_House_Value\"].copy()\n",
    "\n",
    "x_data_train, x_data_test, y_data_train, y_data_test = train_test_split(dataset_features, dataset_labels, train_size=0.7, random_state = 0)\n",
    "#It separates the features (input variables) and the labels (target variable) from the dataset DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31812e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_test #30% of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_train #labels for 70% of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c5b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_test  #labels for 30% of test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b05680",
   "metadata": {},
   "source": [
    "# APPLYING FEATURE SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f1fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_data_train.iloc[:, :] = sc.fit_transform(x_data_train.iloc[:, :])\n",
    "x_data_test.iloc[:, :] = sc.transform(x_data_test.iloc[:, :])\n",
    "\n",
    "#The code you provided applies feature scaling to the training and testing sets using the StandardScaler from scikit-learn.\n",
    "#By performing feature scaling, you ensure that the features in both the training and testing sets have a similar scale, \n",
    "#The StandardScaler scales the features such that they have zero mean and unit variance, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c508db5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_data_train.describe()  #scaled data summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5d7b53",
   "metadata": {},
   "source": [
    "# APPLYING ALGORITHMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0be8ac",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d7030",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LinearRegression()\n",
    "\n",
    "linear_model.fit(x_data_train, y_data_train)\n",
    "\n",
    "predicted_price = linear_model.predict(x_data_test)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f3249c",
   "metadata": {},
   "source": [
    "__Now our model has been trained on the training dataset.__ <br>\n",
    "__Predicting and evaluating the performance of the model.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3daccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_data_test, predicted_price))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_data_test, predicted_price))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_data_test, predicted_price)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97f7ac0",
   "metadata": {},
   "source": [
    "__The lesser the values for these metrics, the better is the performance of the algorithms.__ <br>\n",
    "__Let us move to other algorithms.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf54babb",
   "metadata": {},
   "source": [
    "## Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4154949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeRegressor()\n",
    "\n",
    "dt_model.fit(x_data_train, y_data_train)\n",
    "#This line fits the decision tree regression model to the training data.\n",
    "\n",
    "predicted_price = dt_model.predict(x_data_test)\n",
    "#takes the testing features as input and returns the predicted target values based on the learned decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc5e501",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_data_test, predicted_price))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_data_test, predicted_price))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_data_test, predicted_price)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75272071",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ead1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "knn_model.fit(x_data_train, y_data_train)\n",
    "\n",
    "predicted_price = knn_model.predict(x_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbff547",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_data_test, predicted_price))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_data_test, predicted_price))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_data_test, predicted_price)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14be6aeb",
   "metadata": {},
   "source": [
    "__This is better from above models but it is not a great score.__<br>\n",
    "__The Median_House_Value ranges between 14999 to 500000 so this typical prediction error is not very satisfying.__<br>\n",
    "__Let us move to other algorithms.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb830aa",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "rf_model.fit(x_data_train.values, y_data_train)\n",
    "\n",
    "\n",
    "predicted_price = rf_model.predict(x_data_test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d22e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_data_test, predicted_price))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_data_test, predicted_price))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_data_test, predicted_price)))\n",
    "\n",
    "# Lower values of MAE, MSE, and RMSE indicate better predictive accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e06dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the trained random forest regression model (rf_model) is already available\n",
    "\n",
    "# Custom input\n",
    "custom_input = [[8.3252,41,880,129,322,126,37.88,-122.23,9263.040773,556529.158342,735501.806984,67432.517001,21250.213767]]  # Example custom input, modify as needed\n",
    "\n",
    "# Predict the target variable\n",
    "predicted_value = rf_model.predict(custom_input)\n",
    "\n",
    "# Print the predicted value\n",
    "print(\"Predicted Value: $\",predicted_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa799a8-e7f7-4c81-9095-ad4a19af88d4",
   "metadata": {},
   "source": [
    "__This is much Better.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712857d2-652b-4e61-8f5a-0eea1adcb771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#The pickle module in Python is used for object serialization and deserialization. \n",
    "#It allows you to save Python objects to disk in a binary format and later load them back into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c759607-769d-4594-a99a-2c7116f95ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model as .pkl file\n",
    "\n",
    "pkl_filename = \"model.pkl\" #This line defines the filename (model.pkl) that you want to use to save the trained model.\n",
    "\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(rf_model, file)\n",
    "    \n",
    "#This block of code opens the file specified by pkl_filename in write binary mode ('wb').\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03dfde7-2dfe-4be6-b8ae-b13db015cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the saved model accuracy\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    pickle_model = pickle.load(file)   # load the model from the model.pkl file into the pickle_model object.\n",
    "score = pickle_model.score(x_data_test.values, y_data_test) #calculation of accuracy on the test data and its labels\n",
    "#score: method returns the coefficient of determination R-squared of the model,\n",
    "# A higher R-squared value indicates a better fit of the model to the data.\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6ae7a0",
   "metadata": {},
   "source": [
    "# CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e6bd9",
   "metadata": {},
   "source": [
    "In this study the four machine learning regression algorithms __Linear Regression__, __Decision Tree Regression__, __K-Nearest neighbour__ and __Random forest regression__ have been compared when trained and tested with the dataset.\n",
    "\n",
    "This has been done in order to study how __accurately__ they, as machine learning methods, predict the prices for the house pricing problem.\n",
    "\n",
    "I have found that the __Random forest regression algorithm performs better__ at predicting house prices than other with regards to all of the error metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89007e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "958fa175bb45a12c9a848c5bb7c008c123cf40c0c37e574e566cb4a4d369d0f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
